---
title: "SSCM Exercise 5"
author: "Nikolaus Czernin - 11721138"
output: pdf_document
fig_height: 4 

---

```{r}
library("tidyverse")
library(knitr)

# Custom print function
print_ <- function(...) print(paste(...))

set.seed(11721138)
```
# Task 1
```{r}
x1 <- c(-0.673, -0.584, 0.572, -0.341, -0.218, 0.603, -0.415, -0.013, 0.763, 0.804, 0.054, 1.746, -0.472, 1.638, -0.578, 0.947, -0.329, -0.188, 0.794, 0.894, -1.227, 1.059)
x2 <- c(0.913, -0.639, 2.99, -5.004, 3.118, 0.1, 1.128, 0.579, 0.32, -0.488, -0.994, -0.212, 0.413, 1.401, 0.007, 0.568, -0.005, 0.696)

data.frame(
  Sample=c("x1", "x2"), 
  Mean = c(mean(x1), mean(x2))
) %>% kable()

```

## Plotting
```{r}

# Means
mean_x1 <- mean(x1)
mean_x2 <- mean(x2)

boxplot(x1, x2, 
        horizontal = TRUE, 
        names = c("x1", "x2"),
        main = "Boxplot with means as dots",
        col = c("lightblue", "lightcoral")
        )

points(mean_x1, 1, cex=2 , pch = 18)
points(mean_x2, 2 , cex=2, pch = 18)


```
Looking at the boxplots, the means seem to be pretty much the same almost. 
The first sample has fewer outliers though, a wider outer quantile distance and is more 
right-skewed. 

## Bootstrapping
```{r BS non-param}

bootstrap.t.indep <- function(data.1, data.2, m=10000, ...) {
  # compute the original test-statistic
  original.t <- t.test(x1, x2)$statistic
  # generate bootstrap samples
  bs.samples.1 <- lapply(1:m, function(x) sample(data.1, replace = TRUE))
  bs.samples.2 <- lapply(1:m, function(x) sample(data.2, replace = TRUE))
  # compute the estimated parameters of the samples
  bs.ts <- sapply(1:m, function(i) t.test(bs.samples.1[[i]], bs.samples.2[[i]])$statistic)
  # we now have a student's t distribution
  # we can extract the p-value from it
  p.value = mean(abs(bs.ts) >= abs(original.t))
  # also get the confidence intervals, i.e. the quantiles of the t-stats
  ci.95 <- quantile(bs.ts, c(0.05, 0.95))
  ci.99 <- quantile(bs.ts, c(0.01, 0.99))
  # return whatever was created here
  list(p.value = p.value, ci.95 = ci.95, ci.99 = ci.99)
}

bootstrap.t.indep(x1, x2, m=30)
```
Here I define a function for non-parametric bootstrapping as a test. 
The function first computes the estimator, in this case the student's t-test on 
the original two samples. It then iterates m times and each time applys
non-parametric bootstrapping by sampling from the original samples with replacement 
to create 2 new samples, which are compared again with t tests. 
The t statistics of these m tests form a sort of student's t distribution, 
for wich I calculate a p value and confidence intervals. 

```{r BS centered}
bootstrap.t.centered <- function(data.1, data.2, m=10000) {
  # compute the mean of the combined samples
  mean.center <- mean(c(data.1, data.2))
  print("Centering the means by" %>% paste(-mean.center %>% round(3)))
  # center the 2 samples
  data.1 <- data.1 - mean.center
  data.2 <- data.2 - mean.center
  # apply the independent bootstrap esimation
  bootstrap.t.indep(data.1, data.2, m=m)

  }

bootstrap.t.centered(x1, x2, m=30)

```
The function here works similarly to the one before, it only applies 
combined mean centering before generating samples and applying the estimators beforehand. 

## Applying the functions on t-tests
```{r}

results.bootstrap.t.indep <- bootstrap.t.indep(x1, x2)
results.bootstrap.t.centered <- bootstrap.t.centered(x1, x2)

res <- data.frame(
  Independed.Bootstrap.Sampling=c(
    results.bootstrap.t.indep$ci.95 %>% round(4) %>% paste(collapse = " - "), 
    results.bootstrap.t.indep$ci.99 %>% round(4) %>% paste(collapse = " - "),
    results.bootstrap.t.indep$p.value
  ),
  Mean.Centered.Bootstrap.Sampling=c(
    results.bootstrap.t.centered$ci.95 %>% round(4) %>% paste(collapse = " - "), 
    results.bootstrap.t.centered$ci.99 %>% round(4) %>% paste(collapse = " - "),
    results.bootstrap.t.centered$p.value
  )
) 

rownames(res) <- c("95% Conf.Level", "99% Conf.Level", "p-Value")
res %>% 
  kable(caption="Comparison of Bootstrap Sampling methods on t-tests")
  
  
  

```
Im getting p-values well over 0.9, so we are far from being able to reject the 
null-hypothesis of the samples having different means.  


## Permutation

```{r}
permutation_test <- function(data.1, data.2, m=4){
  # get the t statistic of the original samples
  t.original <- t.test(data.1, data.2)$statistic
  # combine the datasets
  data.combined <- c(data.1, data.2)
  # create bootstrap samples from the combined data
  t.bs <- sapply(1:m, function(x) {
    # create a permutation of the combined dataset
    permutation_idx <- sample(1:length(data.combined), size = length(data.1), replace = FALSE)
    # get 2 samples at the sizes of the original samples
    permutation.1 <- data.combined[permutation_idx]
    permutation.2 <- data.combined[-permutation_idx]
    # perform a t test and return the t statistic
    t.test(permutation.1, permutation.2)$statistic
  })
  
  # calculate the p value
  p.value <- mean(abs(t.bs) >= abs(t.original))
  # also get the confidence intervals, i.e. the quantiles of the t-stats
  ci.95 <- quantile(t.bs, c(0.05, 0.95))
  ci.99 <- quantile(t.bs, c(0.01, 0.99))
  # return whatever was created here
  list(p.value = p.value, ci.95 = ci.95, ci.99 = ci.99)
  
}



results.permutation_test <- permutation_test(x1, x2, m=10000)

res <- data.frame(
  "Independed Bootstrap Sampling"=c(
    results.permutation_test$ci.95 %>% round(4) %>% paste(collapse = " - "), 
    results.permutation_test$ci.99 %>% round(4) %>% paste(collapse = " - "),
    results.permutation_test$p.value
  )
) 

rownames(res) <- c("95% Conf.Level", "99% Conf.Level", "p-Value")
res %>% 
  kable(caption="Permutation Sampling method on t-tests")
  
  
```
Instead of adapting the first test function I made, I implemented a new function. 
It again creates a function that iterates m times and applies a t-test on random 
index permutations of the combined dataset. Using the same formula as before I 
calculate the p values and the confidence intervals on the t statistics of the 
m students t test statistics.  

The p value of the test is again ~0.9, so we are not rejecting the Null-hypothesis 
of the two samples having different means. 

## T-Test and Wilcoxon test
```{r}
t.test(x1, x2)
wilcox.test(x1, x2)
```
The results of the base R `t.test()` also has a p-value of ~0.9, which is in line 
with my simulated tests and my conclusion of keeping the null-hypothesis. 

The p-value of the Mann-Whitney test is ~0.66, which is also high enough for us 
not to be able to reject the null-hypothesis. 




# Task 2

```{r}
# define function to sample the used variables from their distributions
getx1 <- function(n=1) rnorm(n, 2, sqrt(3))
getx2 <- function(n=1) runif(n, 2, 4)
getx3 <- function(n=1) runif(n, -2, 2)
gete <-  function(n=1) rt(n, df=5)

# define the function y
gety <- function(x1, x2, e){
  3 + 2 * x1 + x2 + e
}

# Generate a sample of size n
data <- 200 %>% 
  data.frame(
    x1=getx1(.),
    x2=getx2(.),
    x3=getx3(.),
    e =gete(.)
  ) %>% 
  mutate(y=gety(x1, x2, e)) %>% 
  select(-".") 

data %>% head()


```
I define functions that source the variables from their respective distributions 
and can be passed to the y function to create the model output. 
I use piping to create a dataframe of size 200 with all parameters and the output 
variable y. 


## Residual bootstrap

```{r}
# fitting the linear model
lin <- lm(y~., data=data)
lin %>% summary()

yhat <- predict(lin, data %>% select(-y))
plot(
  data$y,
  yhat,
  main="Prediction plot of the linear model", ylab="predicted", xlab="observed"
)
```
In the linear model, all included variables are significant, even x3, which played 
no part in creating the output variable and essentially distorts the data, but its 
coefficient is nearly zero.  
Looking at the prediction plot, we can tell that the model is nearly perfect and 
the predictions form a perfectly straight line when plotted against the actual y values. 

```{r}
# get the residuals
residuals <- resid(lin)
# create the bootstrap sample
bootstrap.coefficients <- function(yhat, residuals, m=10000){
    # generate new residuals via bootstrapping, m times
    residuals.resampled <- sapply(1:m, function(x) sample(residuals, replace = TRUE))
    # create new predictions by adding the sampled residuals
    yhat.bootstrapped <- sapply(residuals.resampled, function(rs) yhat + rs)
    # fit a new model to the bootstrapped predictions, without using e (epsilon)
    new.model <- lm(yhat.bootstrapped ~ x1 + x2 + x3, data=data)
    # return the coefficients of the bootstrapped model
    coef(new.model)
}

bootstrap.coefficients(yhat, residuals)

```



